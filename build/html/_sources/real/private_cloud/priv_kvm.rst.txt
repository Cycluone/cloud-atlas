.. _priv_kvm:

=======================
私有云KVM环境
=======================

运行环境
=========

- 物理服务器: :ref:`hpe_dl360_gen9`

- 按照 :ref:`ubuntu_deploy_kvm` 安装部署好基础KVM运行环境::

   sudo apt install qemu-kvm libvirt-daemon-system libvirt-clients bridge-utils virtinst

   sudo adduser `id -un` libvirt
   sudo adduser `id -un` kvm

- 然后确认运行环境正常::

   $ virsh list --all
    Id    Name                           State
   ----------------------------------------------------

设置交换网络
=============

虽然在测试环境中，我们常常使用 :ref:`libvirt_nat_network` ，但是我在部署 :ref:`hpe_dl360_gen9` 和 :ref:`pi_cluster` 是通过物理交换机连接的，也就是说，所有数据通讯都是通过真实网络传输，所以我们需要采用 :ref:`libvirt_bridged_network` :

- 通讯通过DL360服务器的 ``eno1`` 网口，网段是 ``192.168.6.0/24`` ::

   ip address show eno1

显示::

   2: eno1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
       link/ether 94:57:a5:5a:d9:c0 brd ff:ff:ff:ff:ff:ff
       inet 192.168.6.200/24 brd 192.168.6.255 scope global eno1
          valid_lft forever preferred_lft forever
       inet6 fe80::9657:a5ff:fe5a:d9c0/64 scope link
          valid_lft forever preferred_lft forever

- 创建 ``/etc/sysctl.d/bridge.conf`` 以下设置(性能和安全原因)::

   net.bridge.bridge-nf-call-ip6tables=0
   net.bridge.bridge-nf-call-iptables=0
   net.bridge.bridge-nf-call-arptables=0

配置生效::

   sysctl -p /etc/sysctl.d/bridge.conf

- 创建 ``/etc/udev/rules.d/99-bridge.rules`` ，这个udev规则将在加载bridge模块式执行上述sysctl规则::

   ACTION=="add", SUBSYSTEM=="module", KERNEL=="bridge", RUN+="/sbin/sysctl -p /etc/sysctl.d/bridge.conf"

.. note::

   实现bridge网络有多种方法，为了和Ubuntu Server默认的 :ref:`netplan` 管理方法一致，这里采用 netplan 来实现bridge

- 配置 ``/etc/netplan/00-cloud-init.yaml``

.. literalinclude:: ../../kvm/libvirt/network/libvirt_bridged_network/00-cloud-init.yaml
   :language: yaml
   :linenos:
   :caption: /etc/netplan/00-cloud-init.yaml

执行生效::

   sudo netplan generate
   sudo netplan apply

创建模版虚拟机
===================

.. note::

   注意，如果是普通用户执行 ``virt-install`` 会提示错误::

      WARNING  /home/huatai/.cache/virt-manager/boot may not be accessible by the hypervisor. You will need to grant the 'libvirt-qemu' user search permissions for the following directories: ['/home/huatai/.cache']

   需要修复这个权限才能正常安装::

      chmod 770 ~/.cache
      sudo adduser libvirt-qemu staff

   不过还是报错::

      [  219.477216 ] dracut-initqueue[736]: Warning: dracut-initqueue timeout - starting timeout scripts

- 安装 ``libosinfo-bin`` 就可以使用 ``osinfo-query --os-variant`` 查询可以支持的操作系统类型

- 创建CentOS 7模版::

   virt-install \
     --network bridge:virbr0 \
     --name centos7 \
     --ram=2048 \
     --vcpus=1 \
     --os-type=centos7.0 \
     --disk path=/var/lib/libvirt/images/centos7.qcow2,format=qcow2,bus=virtio,cache=none,size=6 \
     --graphics none \
     --location=http://mirrors.163.com/centos/7/os/x86_64/ \
     --extra-args="console=tty0 console=ttyS0,115200" 

.. note::

   请注意，这里 ``--network bridge:virbr0`` 是使用了 :ref:`libvirt_nat_network` ，而没有直接使用前面创建的的 :ref:`libvirt_bridged_network` ``br0`` ，这是因为发现初次安装guest内部内核还是需要访问internet，否则会出现报错 :ref:`dracut-initqueue_timeout` 。

   模版操作系统通过NAT方式完成安装，再clone出来的虚拟机连接Bridge网络，则可以通过设置 :ref:`apt_proxy_arch` 完成后续更新和部署。

- 创建CentOS 8模版::

   virt-install \
     --network bridge:virbr0 \
     --name centos8 \
     --ram=2048 \
     --vcpus=1 \
     --os-type=centos8 \
     --disk path=/var/lib/libvirt/images/centos8.qcow2,format=qcow2,bus=virtio,cache=none,size=6 \
     --graphics none \
     --location=http://mirrors.163.com/centos/8/BaseOS/x86_64/os/ \
     --extra-args="console=tty0 console=ttyS0,115200" 

.. note::

   构建 Ubuntu 模版guest系统，则参考 :ref:`create_vm` 

虚拟机串口设置
----------------

.. note::

   通过上述串口控制台安装的CentOS 7虚拟机，已经默认在Guest OS的内核启动参数中添加了 ``console=ttyS0,115200`` ，所以可以直接在Host主机上使用 ``virsh console <虚拟机>`` 访问虚拟机控制台。

   如果是早期CentOS 版本，可能默认没有配置串口输出，则在guest系统的 ``/etc/default/grub`` 中设置::

      GRUB_TERMINAL="serial console"
      GRUB_SERIAL_COMMAND="serial --speed=115200"
      GRUB_CMDLINE_LINUX="crashkernel=auto console=ttyS0,115200"

静态IP
---------

为了方便管理模版主机，设置各个模版主机IP地址为 ``192.168.122.x`` ，所以需要按照 :ref:`libvirt_static_ip_in_studio` 将 ``default`` 网络的DHCP分配IP段空出一部分给固定IP地址

- 编辑默认网络::

   virsh net-edit default

将::

   <dhcp>
     <range start='192.168.122.2' end='192.168.122.254'/>
   </dhcp>

修改成::

   <dhcp>
     <range start='192.168.122.51' end='192.168.122.254'/>
   </dhcp>

- 然后重新生成libvirt网络::

   virsh  net-destroy default
   virsh  net-start default

- 重新将虚拟机网络连接到default网络::

   brctl addif virbr0 vnet0
   brctl addif virbr0 vnet1
   ...

- 通过 ``virsh console centos7`` 连接到虚拟机控制台，然后登录系统，修订 ``/etc/sysconfig/network-scripts/ifcfg-eth0`` 配置，设置静态IP地址::

   # Generated by dracut initrd
   NAME="eth0"
   HWADDR="52:54:00:d0:84:1f"
   ONBOOT=yes
   NETBOOT=yes
   UUID="d5a03523-af20-4aff-af1c-4a4393219707"
   TYPE=Ethernet

   # 以下新加
   IPV6INIT=no
   BOOTPROTO=static
   IPADDR=192.168.122.42
   NETMASK=255.255.255.0
   GATEWAY=192.168.122.1
   DNS1=192.168.122.1

然后在控制台重启生效::

   /etc/init.d/network restart

复制KVM虚拟机(Kubernetes Master)
=====================================

.. note::

   详细克隆KVM虚拟机请参考 :ref:`clone_vm` 。

   准备 :ref:`priv_docker` 中作为 kubemaster 服务器的虚拟机，详细架构解析请参考 

- 暂停虚拟机::

   virsh suspend centos7

- clone虚拟机::

   virt-clone --connect qemu:///system --original centos7 --name kubemaster-1 --file /var/lib/libvirt/images/kubemaster-1.qcow2

.. note::

   分别在3台物理服务器上创建 ``kubemaster-1`` ``kubemaster-2`` 和 ``kubemaster-3`` 。

- 使用 ``virt-sysprep`` 初始化虚拟机::

   virt-sysprep -d kubemaster-1 --hostname kubemaster-1 --root-password password:CHANGE_ME

.. note::

   如果要保留一些设置，可以参考 `How to reset a KVM clone virtual Machines with virt-sysprep on Linux <https://www.cyberciti.biz/faq/reset-a-kvm-clone-virtual-machines-with-virt-sysprep-on-linux/>`_ 做一些重置调整::

      virt-sysprep -d nullstack --hostname nullstack \
        --run 'sed -i "s/192.168.122.3/192.168.122.10/" /etc/sysconfig/network-scripts/ifcfg-eth0' \
        --keep-user-accounts huatai --keep-user-accounts root

- 启动虚拟机，进一步定制::

   virsh start kubemaster-1


