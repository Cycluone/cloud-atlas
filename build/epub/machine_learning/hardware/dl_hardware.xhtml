<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>深度学习硬件指南</title>
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/epub.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/theme_overrides.css" type="text/css" /> 
  </head><body>

    <div class="document">
      <div class="documentwrapper">
          <div class="body" role="main">
            
  <section id="dl-hardware">
<span id="id1"></span><h1>深度学习硬件指南</h1>
<section id="gpu">
<h2>GPU</h2>
<p>虽然机器学习也可以通过CPU来完成，但是GPU可以极大加速深度学习应用程序，相对时间精力而言，采用GPU是合适的选择。</p>
<p>在选择GPU时需要注意避免:</p>
<ul class="simple">
<li><p>性能不佳硬件</p></li>
<li><p>内存不足</p></li>
<li><p>冷却不佳</p></li>
</ul>
<p>选购PCIe接口GPU卡</p>
</section>
<section id="ram">
<h2>RAM</h2>
<p>我个人感觉内存只最值得投资的能够获得较大性能提升的硬件。需要注意，采用时钟频率高的能够承担成本的最好的内存。</p>
<p>虽然机器学习的性能和内存大小无关，但是为了避免GPU执行代码在执行时被交换到磁盘，需要配置足够的RAM，也就是GPU所配置对等大小内存。例如使用24G内存的Titan RTX，你就至少需要配置24G内存。不过，如果你使用更多GPU并不需要更多内存。</p>
<p>不过，即使内存大小已经匹配了GPU卡上的内存量，仍然可能在处理极大的数据集出现内存不足。所以通常你应该购买经济能够承受的最大量的内存。</p>
</section>
<section id="cpu">
<h2>CPU</h2>
<p>机器学习使用GPU加速，则对CPU没有太大要求。</p>
</section>
<section id="cpupcie">
<h2>CPU和PCIe</h2>
<p>在CPU内存和GPU内存间传输数据就需要通过PCIe接口，所以PCIe带宽非常重要。特别是加载ImageNet训练图片集。不过，现在PCIe的带宽极大，通常除非使用了大量的GPU设备，例如4个GPU设备，则需要考虑PCIe通道是否足够，否则不需要太关注。</p>
</section>
<section id="id2">
<h2>CPU核心</h2>
<p>在深度学习中，很少有计算需要由CPU负责。不过需要观察实际运算时负载。</p>
</section>
<section id="ssd">
<h2>硬盘/SSD</h2>
<p>在深度学习中，硬盘驱动器通常不是瓶颈。通常在数据从磁盘加载是需要考虑磁盘性能。通常磁盘性能都能够满足要求，不过购买SSD磁盘依然是值得的，甚至可以购买NVMe SSD以获得比常规SSD更好的性能。</p>
</section>
<section id="id3">
<h2>电源</h2>
<p>电源是不应该忽视的组件，特别是GPU通常会消耗更多的电能。而且机器学习会需要大量时间演算，所以电源也非常重要。</p>
</section>
<section id="cpugpu">
<h2>CPU和GPU冷却</h2>
<p>对于现代计算机系统，高速运行产生大量的热量，需要及时组号设备冷却，否则会导致异常不稳定现象。</p>
<p>需要部署温度监控程序来见识GPU的温度，及时通过冷却来保证稳定运行。</p>
<div class="admonition note">
<p class="admonition-title">注解</p>
<p>对于个人，我觉得可以通过购买二手服务器以及二手显卡来构建GPU计算集群。在淘宝上有专用于多GPU的渲染AI牧场的服务器，专门设计过可以容纳很多GPU卡。</p>
<p>如果侧重于虚拟化技术，兼顾深度学习，我觉得二手的机架服务器可以用低廉价格换得可靠运行的基座，然后插1~2快GPU卡完成深度学习训练。</p>
<p>对于开始自学入门，可以从 <a class="reference internal" href="../jetson/index.xhtml#jetson"><span class="std std-ref">NVIDIA Jetson</span></a> 这样的ARM结合GPU的廉价设备开始，先熟悉基本的机器学习框架和软件，再逐步根据需求升级硬件。</p>
</div>
</section>
<section id="id4">
<h2>参考</h2>
<ul class="simple">
<li><p><a class="reference external" href="http://timdettmers.com/2018/12/16/deep-learning-hardware-guide/">A Full Hardware Guide to Deep Learning</a><span class="link-target"> [http://timdettmers.com/2018/12/16/deep-learning-hardware-guide/]</span></p></li>
</ul>
</section>
</section>


            <div class="clearer"></div>
          </div>
      </div>
      <div class="clearer"></div>
    </div>
  </body>
</html>